{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pbl_lab_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZX7wKcnM2JtF3BcCrlg/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whispermy/novatus_academia/blob/main/pbl/pbl_lab_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "931ae0d7lMWv",
        "outputId": "b1575f12-1956-4841-ef7e-acd5d28565f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cLRvMhKrsn9k",
        "outputId": "443c1f9d-b7b0-4c31-c30b-ba31b95fa93a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/pbl/trainingData2.csv\")\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INPUT</th>\n",
              "      <th>OUTPUT</th>\n",
              "      <th>종류</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A는 B</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A는 B로 설정</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A는 B로 초기화</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A를 B로</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A에다가 입력받아줘</td>\n",
              "      <td>A = input()</td>\n",
              "      <td>입력</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         INPUT       OUTPUT  종류\n",
              "0         A는 B        A = B  선언\n",
              "1     A는 B로 설정        A = B  선언\n",
              "2    A는 B로 초기화        A = B  선언\n",
              "3       A를 B로         A = B  선언\n",
              "4  A에다가 입력받아줘   A = input()  입력"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOFj4K3ttIuM",
        "outputId": "524504c4-9adb-47cb-f0d7-7cedeafd323a"
      },
      "source": [
        "#형태소 분석기 사용하기 \n",
        "!pip install konlpy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyn0ImZQtNA8",
        "outputId": "135cd730-73c8-4397-a916-6d92d317e385"
      },
      "source": [
        "from konlpy.tag import Kkma, Komoran, Okt, Mecab\n",
        "\n",
        "okt = Okt()\n",
        "txt = data['INPUT'][199]\n",
        "print(okt.pos(txt,norm=True, stem=False, join=False))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('만약', 'Noun'), ('A', 'Alpha'), ('가', 'Verb'), ('NonE', 'Alpha'), ('값', 'Noun'), ('이', 'Josa'), ('아닐', 'Adjective'), ('때', 'Noun')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXsPz05ItWm6",
        "outputId": "52b94ef1-1263-449f-eeb1-4e25f6dfdb17"
      },
      "source": [
        "list_input = []\n",
        "\n",
        "for txt in data['INPUT']:\n",
        "  tokens = okt.pos(txt,norm=True, stem=False, join=False)\n",
        "  s = []\n",
        "  for token in tokens:\n",
        "    s.append(token[0])\n",
        "  list_input.append(s)\n",
        "\n",
        "list_input[:10]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A', '는', 'B'],\n",
              " ['A', '는', 'B', '로', '설정'],\n",
              " ['A', '는', 'B', '로', '초기', '화'],\n",
              " ['A', '를', 'B', '로'],\n",
              " ['A', '에다가', '입력', '받아줘'],\n",
              " ['A', '에', '입력', '받아'],\n",
              " ['A', '에', '문자열', 'B', '로', '초기', '화'],\n",
              " ['A', '를', '문자열', 'B', '로'],\n",
              " ['문자열', 'A', '를', '출력', '해'],\n",
              " ['A', '를', '출력', '해']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vX0Z7Z5td6Y",
        "outputId": "b8a61ab8-e028-4b2a-8a44-6feb6f38d53a"
      },
      "source": [
        "#word2vec\n",
        "from gensim.models import Word2Vec\n",
        "dimension_word = 50\n",
        "# train word2vec model\n",
        "model_input = Word2Vec(list_input, size=dimension_word, window=2, workers=8, min_count=1)\n",
        "# summarize vocabulary size in model\n",
        "words = list(model_input.wv.vocab)\n",
        "print('Vocabulary size: %d' % len(words))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQYtViDkthHj",
        "outputId": "027b0e16-0324-478a-bd17-596fe0e86ae4"
      },
      "source": [
        "input_vector = model_input.wv\n",
        "input_vector['문자열']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00681457,  0.00917972, -0.00020886, -0.00935412, -0.00302224,\n",
              "       -0.00591075, -0.00570885,  0.00386204, -0.00026905,  0.00087248,\n",
              "       -0.00568048,  0.00197433, -0.00766818, -0.00916034, -0.00983635,\n",
              "        0.00131893, -0.00783752,  0.00837995,  0.00357566,  0.00365959,\n",
              "        0.0093515 ,  0.0016174 ,  0.00312651,  0.0004466 , -0.000528  ,\n",
              "       -0.01069359,  0.00861054, -0.00792171,  0.0051148 ,  0.00150896,\n",
              "        0.00715382, -0.00914776, -0.00144025,  0.005483  , -0.00539093,\n",
              "       -0.00331204,  0.01104489, -0.00644086, -0.00263426,  0.005149  ,\n",
              "        0.00761539,  0.00297338,  0.0029197 , -0.00375791, -0.00641774,\n",
              "        0.00374203, -0.00907169,  0.01076811,  0.00312032, -0.00164318],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lYyh9YStkFU",
        "outputId": "00acdd87-5767-4afe-964c-90173f0f33b0"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer_input = Tokenizer(lower=False)\n",
        "tokenizer_input.fit_on_texts(list_input)\n",
        "encoded_input = tokenizer_input.texts_to_sequences(list_input)\n",
        "encoded_input[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 41, 2],\n",
              " [1, 41, 2, 15, 83],\n",
              " [1, 41, 2, 15, 27, 52],\n",
              " [1, 10, 2, 15],\n",
              " [1, 116, 84, 117],\n",
              " [1, 53, 84, 118],\n",
              " [1, 53, 61, 2, 15, 27, 52],\n",
              " [1, 10, 61, 2, 15],\n",
              " [61, 1, 10, 47, 22],\n",
              " [1, 10, 47, 22]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q6xSpy6tm4B",
        "outputId": "8b8f890e-d92c-4f97-a009-8efd58e10da5"
      },
      "source": [
        "#input 가중치 행렬\n",
        "import numpy as np\n",
        "\n",
        "input_vector_dic = {}\n",
        "for key in input_vector.wv.vocab.keys():\n",
        "    input_vector_dic[key] = input_vector[key]\n",
        "input_vector_dic['A']\n",
        "\n",
        "# total vocabulary size plus 0 for unknown words\n",
        "vocab_size=len(tokenizer_input.word_index)+1\n",
        "input_embedding_vectors = np.zeros((vocab_size, dimension_word))\n",
        "for word, i in tokenizer_input.word_index.items():\n",
        "    input_embedding_vectors[i] = input_vector_dic.get(word)\n",
        "\n",
        "input_embedding_vectors[np.isnan(input_embedding_vectors)] = 0\n",
        "\n",
        "#정규화 \n",
        "input_embedding_vectors = input_embedding_vectors / input_embedding_vectors.max(axis=0)\n",
        "\n",
        "input_embedding_vectors.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbIOr24tqt3",
        "outputId": "ef8201ac-761c-41d9-c3c2-69da7ffd6512"
      },
      "source": [
        "list_output_in = []\n",
        "list_output_target = []\n",
        "\n",
        "########################################################\n",
        "######## decoder 의 input 으로 쓸 데이터 만들기 ########\n",
        "########################################################\n",
        "#(decoder의 데이터는 띄어쓰기 단위로 자르기)\n",
        "for txt in data['OUTPUT']:\n",
        "  tokens = txt.split()\n",
        "  s = ['<sos>']\n",
        "  t = []\n",
        "  for token in tokens:\n",
        "    s.append(token)\n",
        "    t.append(token)\n",
        "  list_output_in.append(s)\n",
        "  t.append('<eos>')\n",
        "  list_output_target.append(t)\n",
        "  \n",
        "print(list_output_in[:10])\n",
        "print(list_output_target[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'input()'], ['<sos>', 'A', '=', 'input()'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'print(\"', 'A', '\")'], ['<sos>', 'print(', 'A', ')']]\n",
            "[['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'input()', '<eos>'], ['A', '=', 'input()', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['print(\"', 'A', '\")', '<eos>'], ['print(', 'A', ')', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6wYryMwtu_k"
      },
      "source": [
        "# list_output_target = []\n",
        "\n",
        "########################################################\n",
        "######## decoder 의 output 으로 쓸 데이터 만들기 ########\n",
        "########################################################\n",
        "#(decoder의 데이터는 띄어쓰기 단위로 자르기)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fn8Uri-tw8_",
        "outputId": "2b502099-f385-4c87-c81c-cc5380729752"
      },
      "source": [
        "tokenizer_output = Tokenizer(lower=False)\n",
        "tokenizer_output.fit_on_texts(list_output_in)\n",
        "tokenizer_output.fit_on_texts(list_output_target)\n",
        "\n",
        "encoded_output_in = tokenizer_output.texts_to_sequences(list_output_in)\n",
        "print(encoded_output_in[:10])\n",
        "\n",
        "encoded_output_target = tokenizer_output.texts_to_sequences(list_output_target)\n",
        "print(encoded_output_target[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 1, 17, 2], [4, 1, 17, 2], [4, 1, 17, 2], [4, 1, 17, 2], [4, 1, 17, 35], [4, 1, 17, 35], [4, 1, 17, 2], [4, 1, 17, 2], [4, 36, 1, 37], [4, 31, 1, 15]]\n",
            "[[1, 17, 2, 5], [1, 17, 2, 5], [1, 17, 2, 5], [1, 17, 2, 5], [1, 17, 35, 5], [1, 17, 35, 5], [1, 17, 2, 5], [1, 17, 2, 5], [36, 1, 37, 5], [31, 1, 15, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnQyhiZst3ET",
        "outputId": "afbdb9d0-e04b-4584-a4fd-861fba8a8193"
      },
      "source": [
        "#word2vec\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# train word2vec model\n",
        "model_output = Word2Vec(list_output_in, size=dimension_word, window=2, workers=8, min_count=1)\n",
        "# summarize vocabulary size in model\n",
        "words = list(model_output.wv.vocab)\n",
        "print('Vocabulary size: %d' % len(words))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yep8G-J_t56U",
        "outputId": "64873e09-6138-4ed4-b0b2-8bee9c033a60"
      },
      "source": [
        "output_vector = model_output.wv\n",
        "output_vector['<sos>']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-8.4169966e-04,  3.9573256e-03,  2.8813339e-03,  1.3574884e-02,\n",
              "        1.8430573e-03,  4.7838977e-03,  1.5418289e-02, -9.6278926e-03,\n",
              "       -2.1956677e-03, -9.0154266e-04, -1.1671355e-02, -1.8047931e-03,\n",
              "        1.2494219e-03,  6.2413216e-03,  3.4803294e-03,  2.6611248e-03,\n",
              "       -1.2754852e-02, -6.9268271e-03, -1.2614439e-02,  8.4791677e-03,\n",
              "        1.2013347e-02,  1.0298899e-02,  7.8108098e-04, -1.4120115e-02,\n",
              "       -5.8749504e-03,  1.0336987e-03, -1.7142974e-02,  8.8886339e-03,\n",
              "       -8.0797635e-03, -7.0810150e-03,  1.0404945e-02,  3.0844051e-03,\n",
              "       -9.3434211e-03,  1.4683449e-03, -5.4670451e-03,  8.8499160e-03,\n",
              "       -3.6267838e-03, -7.2699562e-03,  5.0923130e-03, -4.4472530e-03,\n",
              "       -4.3231989e-03,  5.6496612e-03, -6.7574409e-04,  9.9775465e-03,\n",
              "        2.6159456e-03,  1.2899832e-02,  2.0091322e-05,  3.9138389e-03,\n",
              "       -2.1336742e-03,  1.0457357e-02], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHJdwzM8t8PZ"
      },
      "source": [
        "output_vector_dic = {}\n",
        "for key in model_output.wv.vocab.keys():\n",
        "    output_vector_dic[key] = output_vector[key]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOnoeAsxt-jZ",
        "outputId": "a13c6e4b-180d-4f74-fff7-c71f3a2523f7"
      },
      "source": [
        "# total vocabulary size plus 0 for unknown words\n",
        "vocab_size=len(tokenizer_output.word_index)+1\n",
        "output_embedding_vectors = np.zeros((vocab_size, dimension_word))\n",
        "for word, i in tokenizer_output.word_index.items():\n",
        "    output_embedding_vectors[i] = output_vector_dic.get(word)\n",
        "\n",
        "output_embedding_vectors[np.isnan(output_embedding_vectors)] = 0\n",
        "\n",
        "#정규화 \n",
        "output_embedding_vectors = output_embedding_vectors / output_embedding_vectors.max(axis=0)\n",
        "output_embedding_vectors.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPlyB4fuuBNc",
        "outputId": "faf3eac2-a4eb-4e71-ac19-67e113ce5a41"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "encoder_max_length = max([len(s) for s in list_input])\n",
        "encoder_input = pad_sequences(encoded_input, maxlen=encoder_max_length, padding='post')\n",
        "print(encoder_input.shape)\n",
        "\n",
        "decoder_max_length_in = max([len(s) for s in list_output_in])\n",
        "decoder_input = pad_sequences(encoded_output_in, maxlen=decoder_max_length_in, padding='post')\n",
        "print(decoder_input.shape)\n",
        "\n",
        "decoder_max_length_target = max([len(s) for s in list_output_target])\n",
        "decoder_target = pad_sequences(encoded_output_target, maxlen=decoder_max_length_target, padding='post')\n",
        "print(decoder_target.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(257, 26)\n",
            "(257, 14)\n",
            "(257, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHNZ76JZuFXG",
        "outputId": "9df74939-fdf4-40c9-b99c-05899eaefb3d"
      },
      "source": [
        "np.random.seed(50)\n",
        "np.random.shuffle(encoder_input)\n",
        "np.random.seed(50)\n",
        "np.random.shuffle(decoder_input)\n",
        "np.random.seed(50)\n",
        "np.random.shuffle(decoder_target)\n",
        "\n",
        "print(encoder_input[0])\n",
        "print(decoder_input[0])\n",
        "print(decoder_target[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  3  2  4 17 65  5  3  9  6 45  7  8 12  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "[ 4  8  1 20  2 10  6 12  9  3  0  0  0  0]\n",
            "[ 8  1 20  2 10  6 12  9  3  5  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBBM6-oTuD1o"
      },
      "source": [
        "test_ration = int(len(encoder_input) * 0.1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua3EIhtzuH0n"
      },
      "source": [
        "encoder_input_train = encoder_input[:-test_ration]\n",
        "encoder_input_test = encoder_input[-test_ration:]\n",
        "\n",
        "decoder_input_train = decoder_input[:-test_ration]\n",
        "decoder_input_test = decoder_input[-test_ration:]\n",
        "\n",
        "decoder_target_train = decoder_target[:-test_ration]\n",
        "decoder_target_test = decoder_target[-test_ration:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewc_vkQwuHu2",
        "outputId": "a9a95874-5fa2-4201-da4d-b0f622ce854e"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, GRU, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#########################################################################\n",
        "####################encoder 구조를 rnn로 만들어보기######################\n",
        "#########################################################################\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(151,dimension_word,weights=[input_embedding_vectors])(encoder_inputs)\n",
        "encoder_gru = GRU(dimension_word, activation='relu')(enc_emb)\n",
        "encoder_output = encoder_gru\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI9Mrv5tuHej",
        "outputId": "bbd01d7b-e061-4534-b7f8-57d176aba3ff"
      },
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "##################################################################\n",
        "####################decoder 구조 만들기###########################\n",
        "##################################################################\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb = Embedding(45,dimension_word, weights=[output_embedding_vectors])(decoder_inputs)\n",
        "decoder_gru = GRU(dimension_word,return_sequences=True, return_state=True, activation='relu')\n",
        "decoder_outputs,_ = decoder_gru(dec_emb, initial_state=encoder_output)\n",
        "decoder_dense = TimeDistributed(Dense(45, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXe1EMGwuQOv"
      },
      "source": [
        "##################################################################\n",
        "######################모형 연결시키기#############################\n",
        "##################################################################\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7q9ecO7uQL4"
      },
      "source": [
        "##################################################################\n",
        "###################### 모형 컴파일하기 ###########################\n",
        "##################################################################\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9thJBH9uQJF",
        "outputId": "a053b7d4-6c34-4568-f112-745a91fddd7c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 50)     7550        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 50)     2250        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 50)           15300       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, None, 50),   15300       ['embedding_1[0][0]',            \n",
            "                                 (None, 50)]                      'gru[0][0]']                    \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 45)    2295        ['gru_1[0][0]']                  \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,695\n",
            "Trainable params: 42,695\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGbotEl5uQFF",
        "outputId": "706f60a5-be07-4dea-daf9-f0cb2d2c251a"
      },
      "source": [
        "##################################################################\n",
        "###################### 모형 학습시키기 ###########################\n",
        "##################################################################\n",
        "\n",
        "model.fit(x=[encoder_input_train,decoder_input_train], y=decoder_target_train, batch_size=15, epochs=70)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.1040 - acc: 0.9615\n",
            "Epoch 2/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0960 - acc: 0.9643\n",
            "Epoch 3/70\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.0938 - acc: 0.9637\n",
            "Epoch 4/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0853 - acc: 0.9686\n",
            "Epoch 5/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0787 - acc: 0.9689\n",
            "Epoch 6/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0769 - acc: 0.9720\n",
            "Epoch 7/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0735 - acc: 0.9717\n",
            "Epoch 8/70\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.0758 - acc: 0.9704\n",
            "Epoch 9/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0790 - acc: 0.9717\n",
            "Epoch 10/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0803 - acc: 0.9692\n",
            "Epoch 11/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0849 - acc: 0.9661\n",
            "Epoch 12/70\n",
            "16/16 [==============================] - 3s 156ms/step - loss: 0.0830 - acc: 0.9695\n",
            "Epoch 13/70\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.0724 - acc: 0.9744\n",
            "Epoch 14/70\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 0.0682 - acc: 0.9760\n",
            "Epoch 15/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0668 - acc: 0.9760\n",
            "Epoch 16/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0691 - acc: 0.9754\n",
            "Epoch 17/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0966 - acc: 0.9643\n",
            "Epoch 18/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0836 - acc: 0.9701\n",
            "Epoch 19/70\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.0754 - acc: 0.9744\n",
            "Epoch 20/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0619 - acc: 0.9775\n",
            "Epoch 21/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0598 - acc: 0.9806\n",
            "Epoch 22/70\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 0.0567 - acc: 0.9794\n",
            "Epoch 23/70\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 0.0562 - acc: 0.9784\n",
            "Epoch 24/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0561 - acc: 0.9794\n",
            "Epoch 25/70\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 0.0555 - acc: 0.9797\n",
            "Epoch 26/70\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.0582 - acc: 0.9806\n",
            "Epoch 27/70\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.0650 - acc: 0.9784\n",
            "Epoch 28/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0776 - acc: 0.9711\n",
            "Epoch 29/70\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0700 - acc: 0.9754\n",
            "Epoch 30/70\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.0582 - acc: 0.9781\n",
            "Epoch 31/70\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.0499 - acc: 0.9831\n",
            "Epoch 32/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0482 - acc: 0.9852\n",
            "Epoch 33/70\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.0479 - acc: 0.9831\n",
            "Epoch 34/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0503 - acc: 0.9825\n",
            "Epoch 35/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0675 - acc: 0.9748\n",
            "Epoch 36/70\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.1438 - acc: 0.9483\n",
            "Epoch 37/70\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.1095 - acc: 0.9547\n",
            "Epoch 38/70\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.0710 - acc: 0.9723\n",
            "Epoch 39/70\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.0573 - acc: 0.9791\n",
            "Epoch 40/70\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0507 - acc: 0.9837\n",
            "Epoch 41/70\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.0443 - acc: 0.9855\n",
            "Epoch 42/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0396 - acc: 0.9883\n",
            "Epoch 43/70\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0373 - acc: 0.9895\n",
            "Epoch 44/70\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0437 - acc: 0.9843\n",
            "Epoch 45/70\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.0478 - acc: 0.9837\n",
            "Epoch 46/70\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.0465 - acc: 0.9843\n",
            "Epoch 47/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0387 - acc: 0.9861\n",
            "Epoch 48/70\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0359 - acc: 0.9901\n",
            "Epoch 49/70\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0321 - acc: 0.9901\n",
            "Epoch 50/70\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0380 - acc: 0.9868\n",
            "Epoch 51/70\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0384 - acc: 0.9871\n",
            "Epoch 52/70\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.0403 - acc: 0.9852\n",
            "Epoch 53/70\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0579 - acc: 0.9797\n",
            "Epoch 54/70\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.0572 - acc: 0.9797\n",
            "Epoch 55/70\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0577 - acc: 0.9794\n",
            "Epoch 56/70\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 0.0523 - acc: 0.9831\n",
            "Epoch 57/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0416 - acc: 0.9868\n",
            "Epoch 58/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0363 - acc: 0.9883\n",
            "Epoch 59/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0283 - acc: 0.9914\n",
            "Epoch 60/70\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.0273 - acc: 0.9920\n",
            "Epoch 61/70\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0346 - acc: 0.9877\n",
            "Epoch 62/70\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.0419 - acc: 0.9858\n",
            "Epoch 63/70\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.0520 - acc: 0.9825\n",
            "Epoch 64/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0339 - acc: 0.9889\n",
            "Epoch 65/70\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.0394 - acc: 0.9861\n",
            "Epoch 66/70\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.0297 - acc: 0.9905\n",
            "Epoch 67/70\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.0260 - acc: 0.9905\n",
            "Epoch 68/70\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0253 - acc: 0.9926\n",
            "Epoch 69/70\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0256 - acc: 0.9914\n",
            "Epoch 70/70\n",
            "16/16 [==============================] - 2s 157ms/step - loss: 0.0203 - acc: 0.9932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87a6aa8490>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JphIbljuQAI"
      },
      "source": [
        "encoder_model_test = Model(encoder_inputs, encoder_output)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOVLExXuWrt"
      },
      "source": [
        "decoder_states_inputs = Input(shape=(dimension_word, ))\n",
        "dec_emb2 = dec_emb\n",
        "decoder_outputs_test, decoder_states = decoder_gru(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_outputs_test = decoder_dense(decoder_outputs_test)\n",
        "decoder_model = Model([decoder_inputs, decoder_states_inputs], [decoder_outputs_test, decoder_states])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdtMpUA6yyFs"
      },
      "source": [
        "input_to_index = tokenizer_input.word_index\n",
        "index_to_input = tokenizer_input.index_word\n",
        "target_to_index = tokenizer_output.word_index\n",
        "index_to_target = tokenizer_output.index_word"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8HuGB4MvqNX"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  states_value = encoder_model_test.predict(input_seq)\n",
        "\n",
        "  target_seq = np.array(target_to_index['<sos>']).reshape((1,1,1))\n",
        "  decoded_sentence = \"\"\n",
        "  predict_char = \"\"\n",
        "\n",
        "  while True:\n",
        "    output_tokens, state = decoder_model.predict([target_seq, states_value])\n",
        "    predict_char_index = np.argmax(output_tokens[0][0])\n",
        "    predict_char = index_to_target[predict_char_index]\n",
        "\n",
        "    if predict_char == '<eos>':\n",
        "      break\n",
        "    \n",
        "    decoded_sentence = decoded_sentence + ' ' + predict_char\n",
        "    target_seq[0][0] = predict_char_index\n",
        "    states_value = [state]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0YnN1zw4lqh"
      },
      "source": [
        "def seq2input(input_seq):\n",
        "  sentence = \"\"\n",
        "  for i in input_seq:\n",
        "    if i != 0:\n",
        "      sentence = sentence + index_to_input[i] + \" \"\n",
        "  return sentence"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVVI0Cm9-Ijm"
      },
      "source": [
        "def seq2target(input_seq):\n",
        "  sentence = \"\"\n",
        "  for i in input_seq:\n",
        "    if i != 0:\n",
        "      sentence = sentence + index_to_target[i] + \" \"\n",
        "  return sentence"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe0A-_YN-hpp",
        "outputId": "b89a48bb-f6e8-466f-aaac-9edea1beacd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for seq_index in [5,4,3,2,1]:\n",
        "  input_seq = encoder_input_train[seq_index:seq_index+1]\n",
        "  decoded_sentences = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"한국어 : \",seq2input(encoder_input_train[seq_index]))\n",
        "  print(\"정답코드 : \", seq2target(decoder_input_train[seq_index]))\n",
        "  print(\"예측코드 : \", decoded_sentences, \"\\n\")\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 :  만일 A 가 B 보다 작다면 \n",
            "정답코드 :  <sos> if A < B: \n",
            "예측코드 :   if A < B: \n",
            "\n",
            "한국어 :  A 가 B 랑 같거나 C 보다 D 가 작 을 때 까지 돌려줘 \n",
            "정답코드 :  <sos> while A == B or C < D : \n",
            "예측코드 :   while A <= B : \n",
            "\n",
            "한국어 :  만일 A 가 B 랑 다르고 C 가 D 랑 같으면 \n",
            "정답코드 :  <sos> if A != B and C == D : \n",
            "예측코드 :   if A != B and C == D : \n",
            "\n",
            "한국어 :  A 를 출력 해줘 \n",
            "정답코드 :  <sos> print( A ) \n",
            "예측코드 :   print( A ) \n",
            "\n",
            "한국어 :  A 가 B 보다 크거나 C 가 D 랑 같고 E 가 F 보다 클 경우 \n",
            "정답코드 :  <sos> if A > B or C == D and E > F : \n",
            "예측코드 :   if A > B or C == D and E > F : \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGFfx9kp_dqi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}