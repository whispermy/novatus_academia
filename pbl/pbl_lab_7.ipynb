{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pbl_lab_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/9UAvYnNnIZe283C2OgxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whispermy/novatus_academia/blob/main/pbl/pbl_lab_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "931ae0d7lMWv",
        "outputId": "30e799ad-01d9-4fd3-bd4c-1851f9885b67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cLRvMhKrsn9k",
        "outputId": "d5823a97-e323-4486-b109-8cc80418251c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/pbl/trainingData2.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INPUT</th>\n",
              "      <th>OUTPUT</th>\n",
              "      <th>종류</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A는 B</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A는 B로 설정</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A는 B로 초기화</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A를 B로</td>\n",
              "      <td>A = B</td>\n",
              "      <td>선언</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A에다가 입력받아줘</td>\n",
              "      <td>A = input()</td>\n",
              "      <td>입력</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         INPUT       OUTPUT  종류\n",
              "0         A는 B        A = B  선언\n",
              "1     A는 B로 설정        A = B  선언\n",
              "2    A는 B로 초기화        A = B  선언\n",
              "3       A를 B로         A = B  선언\n",
              "4  A에다가 입력받아줘   A = input()  입력"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOFj4K3ttIuM",
        "outputId": "d8387812-0739-4ae7-e030-7ac762f5d149"
      },
      "source": [
        "#형태소 분석기 사용하기 \n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyn0ImZQtNA8",
        "outputId": "786fe2d8-be29-4cd6-f130-260a1ba3f3f0"
      },
      "source": [
        "from konlpy.tag import Kkma, Komoran, Okt, Mecab\n",
        "\n",
        "okt = Okt()\n",
        "txt = data['INPUT'][199]\n",
        "print(okt.pos(txt,norm=True, stem=False, join=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('만약', 'Noun'), ('A', 'Alpha'), ('가', 'Verb'), ('NonE', 'Alpha'), ('값', 'Noun'), ('이', 'Josa'), ('아닐', 'Adjective'), ('때', 'Noun')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXsPz05ItWm6",
        "outputId": "35a2fba9-bb2c-425f-a62c-88eedb05a8c7"
      },
      "source": [
        "list_input = []\n",
        "\n",
        "for txt in data['INPUT']:\n",
        "  tokens = okt.pos(txt,norm=True, stem=False, join=False)\n",
        "  s = []\n",
        "  for token in tokens:\n",
        "    s.append(token[0])\n",
        "  list_input.append(s)\n",
        "\n",
        "list_input[:10]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A', '는', 'B'],\n",
              " ['A', '는', 'B', '로', '설정'],\n",
              " ['A', '는', 'B', '로', '초기', '화'],\n",
              " ['A', '를', 'B', '로'],\n",
              " ['A', '에다가', '입력', '받아줘'],\n",
              " ['A', '에', '입력', '받아'],\n",
              " ['A', '에', '문자열', 'B', '로', '초기', '화'],\n",
              " ['A', '를', '문자열', 'B', '로'],\n",
              " ['문자열', 'A', '를', '출력', '해'],\n",
              " ['A', '를', '출력', '해']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vX0Z7Z5td6Y",
        "outputId": "a68763e6-4b92-4b5a-a604-3b70f32916ce"
      },
      "source": [
        "#word2vec\n",
        "from gensim.models import Word2Vec\n",
        "dimension_word = 50\n",
        "# train word2vec model\n",
        "model_input = Word2Vec(list_input, size=dimension_word, window=2, workers=8, min_count=1)\n",
        "# summarize vocabulary size in model\n",
        "words = list(model_input.wv.vocab)\n",
        "print('Vocabulary size: %d' % len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQYtViDkthHj",
        "outputId": "28513081-c3e6-4379-efdf-c2a6555cf61e"
      },
      "source": [
        "input_vector = model_input.wv\n",
        "input_vector['문자열']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.76404126e-03,  8.46563280e-03,  6.07652077e-03, -5.25879487e-03,\n",
              "       -3.45286122e-03,  1.98760885e-03,  7.48767098e-03, -9.31620225e-03,\n",
              "        1.00731021e-02,  4.14068904e-03,  9.40385181e-03, -5.15341107e-03,\n",
              "       -7.05679599e-03, -1.11462297e-02,  1.71907435e-04,  8.07250105e-03,\n",
              "        2.69089430e-03,  5.37000051e-05, -8.17278051e-04,  6.61294069e-03,\n",
              "       -1.05456915e-02,  5.45349531e-03,  9.33601055e-03, -1.21585536e-03,\n",
              "        7.28258118e-03,  8.58709309e-03,  4.90114884e-03, -4.92287800e-03,\n",
              "        9.67736938e-04, -2.47530593e-03, -4.02876828e-03, -4.40766755e-03,\n",
              "       -8.26888531e-03, -5.33263013e-03,  3.89395375e-03, -5.85786859e-03,\n",
              "       -6.00622781e-03,  7.46226450e-03,  1.60263677e-03,  8.06033029e-04,\n",
              "        8.97885184e-04,  3.35023063e-03, -4.89797676e-03, -8.53381027e-03,\n",
              "       -4.25724871e-03,  5.49170747e-03, -7.88474747e-04,  3.17527330e-03,\n",
              "       -1.54238939e-03, -3.55152087e-03], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lYyh9YStkFU",
        "outputId": "a0401c2f-a270-4494-9304-17dbbfcbf74b"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer_input = Tokenizer(lower=False)\n",
        "tokenizer_input.fit_on_texts(list_input)\n",
        "encoded_input = tokenizer_input.texts_to_sequences(list_input)\n",
        "encoded_input[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 41, 2],\n",
              " [1, 41, 2, 15, 83],\n",
              " [1, 41, 2, 15, 27, 52],\n",
              " [1, 10, 2, 15],\n",
              " [1, 116, 84, 117],\n",
              " [1, 53, 84, 118],\n",
              " [1, 53, 61, 2, 15, 27, 52],\n",
              " [1, 10, 61, 2, 15],\n",
              " [61, 1, 10, 47, 22],\n",
              " [1, 10, 47, 22]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q6xSpy6tm4B",
        "outputId": "b399b6a3-1152-4902-eec3-476e3a59108e"
      },
      "source": [
        "#input 가중치 행렬\n",
        "import numpy as np\n",
        "\n",
        "input_vector_dic = {}\n",
        "for key in input_vector.wv.vocab.keys():\n",
        "    input_vector_dic[key] = input_vector[key]\n",
        "input_vector_dic['A']\n",
        "\n",
        "# total vocabulary size plus 0 for unknown words\n",
        "vocab_size=len(tokenizer_input.word_index)+1\n",
        "input_embedding_vectors = np.zeros((vocab_size, dimension_word))\n",
        "for word, i in tokenizer_input.word_index.items():\n",
        "    input_embedding_vectors[i] = input_vector_dic.get(word)\n",
        "\n",
        "input_embedding_vectors[np.isnan(input_embedding_vectors)] = 0\n",
        "\n",
        "#정규화 \n",
        "input_embedding_vectors = input_embedding_vectors / input_embedding_vectors.max(axis=0)\n",
        "\n",
        "input_embedding_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbIOr24tqt3",
        "outputId": "ccc46330-2afd-4445-e7f4-877169e89b74"
      },
      "source": [
        "list_output_in = []\n",
        "list_output_target = []\n",
        "\n",
        "########################################################\n",
        "######## decoder 의 input 으로 쓸 데이터 만들기 ########\n",
        "########################################################\n",
        "#(decoder의 데이터는 띄어쓰기 단위로 자르기)\n",
        "for txt in data['OUTPUT']:\n",
        "  tokens = txt.split()\n",
        "  s = ['<sos>']\n",
        "  t = []\n",
        "  for token in tokens:\n",
        "    s.append(token)\n",
        "    t.append(token)\n",
        "  list_output_in.append(s)\n",
        "  t.append('<eos>')\n",
        "  list_output_target.append(t)\n",
        "  \n",
        "print(list_output_in[:10])\n",
        "print(list_output_target[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'input()'], ['<sos>', 'A', '=', 'input()'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'A', '=', 'B'], ['<sos>', 'print(\"', 'A', '\")'], ['<sos>', 'print(', 'A', ')']]\n",
            "[['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'input()', '<eos>'], ['A', '=', 'input()', '<eos>'], ['A', '=', 'B', '<eos>'], ['A', '=', 'B', '<eos>'], ['print(\"', 'A', '\")', '<eos>'], ['print(', 'A', ')', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6wYryMwtu_k"
      },
      "source": [
        "# list_output_target = []\n",
        "\n",
        "########################################################\n",
        "######## decoder 의 output 으로 쓸 데이터 만들기 ########\n",
        "########################################################\n",
        "#(decoder의 데이터는 띄어쓰기 단위로 자르기)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fn8Uri-tw8_",
        "outputId": "9d0dc006-aca1-4d86-908c-06c64024277c"
      },
      "source": [
        "tokenizer_output = Tokenizer(lower=False)\n",
        "tokenizer_output.fit_on_texts(list_output_in)\n",
        "tokenizer_output.fit_on_texts(list_output_target)\n",
        "\n",
        "encoded_output_in = tokenizer_output.texts_to_sequences(list_output_in)\n",
        "print(encoded_output_in[:10])\n",
        "\n",
        "encoded_output_target = tokenizer_output.texts_to_sequences(list_output_target)\n",
        "print(encoded_output_target[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 1, 17, 2], [4, 1, 17, 2], [4, 1, 17, 2], [4, 1, 17, 2], [4, 1, 17, 35], [4, 1, 17, 35], [4, 1, 17, 2], [4, 1, 17, 2], [4, 36, 1, 37], [4, 31, 1, 15]]\n",
            "[[1, 17, 2, 5], [1, 17, 2, 5], [1, 17, 2, 5], [1, 17, 2, 5], [1, 17, 35, 5], [1, 17, 35, 5], [1, 17, 2, 5], [1, 17, 2, 5], [36, 1, 37, 5], [31, 1, 15, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnQyhiZst3ET",
        "outputId": "fe8103fb-8202-46b4-cedd-1978dfc81978"
      },
      "source": [
        "#word2vec\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# train word2vec model\n",
        "model_output = Word2Vec(list_output_in, size=dimension_word, window=2, workers=8, min_count=1)\n",
        "# summarize vocabulary size in model\n",
        "words = list(model_output.wv.vocab)\n",
        "print('Vocabulary size: %d' % len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yep8G-J_t56U",
        "outputId": "a0e415c5-db6b-4807-c64e-9f35e405d11e"
      },
      "source": [
        "output_vector = model_output.wv\n",
        "output_vector['<sos>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4058262e-02,  5.5063305e-05,  1.2311778e-03, -3.5225968e-03,\n",
              "       -1.0308884e-03,  9.4542885e-03, -3.0672147e-03, -7.6089692e-03,\n",
              "        8.0764908e-03,  9.7000906e-03, -1.1631525e-02, -1.1188308e-02,\n",
              "       -3.8223807e-03, -1.3168613e-02, -1.2614398e-03, -6.0122106e-03,\n",
              "       -1.2406388e-02, -2.2140185e-03, -6.3734739e-03, -1.2454268e-02,\n",
              "        5.2389577e-03, -2.4734356e-03,  1.8475259e-04, -1.1181596e-02,\n",
              "       -2.1001678e-03, -8.9886095e-03, -1.0086668e-02, -8.5689100e-03,\n",
              "        9.9031357e-03, -9.1238590e-03,  1.2742590e-02,  5.9764180e-03,\n",
              "        2.7814996e-03, -3.4800558e-03, -5.7395771e-03, -9.3580838e-03,\n",
              "        1.5456112e-03, -1.3557404e-02, -3.4456886e-04, -8.8452324e-03,\n",
              "       -4.7580223e-03, -3.1288785e-03,  1.3976433e-02, -5.0580688e-03,\n",
              "        1.9398787e-03,  5.8600400e-03, -7.4126460e-03,  1.5291342e-02,\n",
              "        3.2823028e-03, -1.1630162e-02], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHJdwzM8t8PZ"
      },
      "source": [
        "output_vector_dic = {}\n",
        "for key in model_output.wv.vocab.keys():\n",
        "    output_vector_dic[key] = output_vector[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOnoeAsxt-jZ",
        "outputId": "fe87c13f-280f-4ed3-a220-986ccbae171f"
      },
      "source": [
        "# total vocabulary size plus 0 for unknown words\n",
        "vocab_size=len(tokenizer_output.word_index)+1\n",
        "output_embedding_vectors = np.zeros((vocab_size, dimension_word))\n",
        "for word, i in tokenizer_output.word_index.items():\n",
        "    output_embedding_vectors[i] = output_vector_dic.get(word)\n",
        "\n",
        "output_embedding_vectors[np.isnan(output_embedding_vectors)] = 0\n",
        "\n",
        "#정규화 \n",
        "output_embedding_vectors = output_embedding_vectors / output_embedding_vectors.max(axis=0)\n",
        "output_embedding_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPlyB4fuuBNc",
        "outputId": "4521c212-b784-41a3-ba10-803464585e7e"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "encoder_max_length = max([len(s) for s in list_input])\n",
        "encoder_input = pad_sequences(encoded_input, maxlen=encoder_max_length, padding='post')\n",
        "print(encoder_input.shape)\n",
        "\n",
        "decoder_max_length_in = max([len(s) for s in list_output_in])\n",
        "decoder_input = pad_sequences(encoded_output_in, maxlen=decoder_max_length_in, padding='post')\n",
        "print(decoder_input.shape)\n",
        "\n",
        "decoder_max_length_target = max([len(s) for s in list_output_target])\n",
        "decoder_target = pad_sequences(encoded_output_target, maxlen=decoder_max_length_target, padding='post')\n",
        "print(decoder_target.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(257, 26)\n",
            "(257, 14)\n",
            "(257, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHNZ76JZuFXG",
        "outputId": "2dbf2245-e16c-4bba-8161-b3cf91ea6938"
      },
      "source": [
        "np.random.seed(50)\n",
        "np.random.shuffle(encoder_input)\n",
        "np.random.seed(50)\n",
        "np.random.shuffle(decoder_input)\n",
        "np.random.seed(50)\n",
        "np.random.shuffle(decoder_target)\n",
        "\n",
        "print(encoder_input[0])\n",
        "print(decoder_input[0])\n",
        "print(decoder_target[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  3  2  4 17 65  5  3  9  6 45  7  8 12  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "[ 4  8  1 20  2 10  6 12  9  3  0  0  0  0]\n",
            "[ 8  1 20  2 10  6 12  9  3  5  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBBM6-oTuD1o"
      },
      "source": [
        "test_ration = int(len(encoder_input) * 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua3EIhtzuH0n"
      },
      "source": [
        "encoder_input_train = encoder_input[:-test_ration]\n",
        "encoder_input_test = encoder_input[-test_ration:]\n",
        "\n",
        "decoder_input_train = decoder_input[:-test_ration]\n",
        "decoder_input_test = decoder_input[-test_ration:]\n",
        "\n",
        "decoder_target_train = decoder_target[:-test_ration]\n",
        "decoder_target_test = decoder_target[-test_ration:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewc_vkQwuHu2",
        "outputId": "05b59c7b-b331-4fa7-e1d4-5e994cd0b283"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, GRU, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#########################################################################\n",
        "####################encoder 구조를 rnn로 만들어보기######################\n",
        "#########################################################################\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(151,dimension_word,weights=[input_embedding_vectors])(encoder_inputs)\n",
        "encoder_gru = GRU(dimension_word, activation='relu')(enc_emb)\n",
        "encoder_output = encoder_gru\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI9Mrv5tuHej",
        "outputId": "df541d91-249a-4b79-b23f-6ff0cb755818"
      },
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "##################################################################\n",
        "####################decoder 구조 만들기###########################\n",
        "##################################################################\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb = Embedding(45,dimension_word, weights=[output_embedding_vectors])(decoder_inputs)\n",
        "decoder_gru = GRU(dimension_word,return_sequences=True, return_state=True, activation='relu')\n",
        "decoder_outputs,_ = decoder_gru(dec_emb, initial_state=encoder_output)\n",
        "decoder_dense = TimeDistributed(Dense(45, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXe1EMGwuQOv"
      },
      "source": [
        "##################################################################\n",
        "######################모형 연결시키기#############################\n",
        "##################################################################\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7q9ecO7uQL4"
      },
      "source": [
        "##################################################################\n",
        "###################### 모형 컴파일하기 ###########################\n",
        "##################################################################\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9thJBH9uQJF",
        "outputId": "be94cad7-3cf7-4773-dc1d-e6e8def11424"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 50)     7550        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, None, 50)     2250        ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 50)           15300       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " gru_5 (GRU)                    [(None, None, 50),   15300       ['embedding_6[0][0]',            \n",
            "                                 (None, 50)]                      'gru[0][0]']                    \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 45)    2295        ['gru_5[0][0]']                  \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,695\n",
            "Trainable params: 42,695\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGbotEl5uQFF",
        "outputId": "e533b060-1a98-4da7-a1ec-296ecf6da357"
      },
      "source": [
        "##################################################################\n",
        "###################### 모형 학습시키기 ###########################\n",
        "##################################################################\n",
        "\n",
        "model.fit(x=[encoder_input_train,decoder_input_train], y=decoder_target_train, batch_size=10, epochs=50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 11s 169ms/step - loss: 3.5882 - acc: 0.4267\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 2.2474 - acc: 0.5511\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 1.3913 - acc: 0.6438\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 1.0498 - acc: 0.7244\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.8493 - acc: 0.7669\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.7110 - acc: 0.7986\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.6148 - acc: 0.8177\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.5329 - acc: 0.8368\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 4s 168ms/step - loss: 0.4761 - acc: 0.8491\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 4s 169ms/step - loss: 0.4247 - acc: 0.8624\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.3914 - acc: 0.8732\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 0.3700 - acc: 0.8750\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 0.3380 - acc: 0.8870\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.3366 - acc: 0.8867\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.3108 - acc: 0.8975\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.3015 - acc: 0.8981\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.2973 - acc: 0.8984\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.3013 - acc: 0.8966\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.2787 - acc: 0.9079\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.2702 - acc: 0.9036\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.2598 - acc: 0.9079\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.2606 - acc: 0.9021\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.2546 - acc: 0.9046\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.2664 - acc: 0.8987\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 4s 174ms/step - loss: 0.2479 - acc: 0.9113\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 4s 168ms/step - loss: 0.2462 - acc: 0.9138\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 0.2424 - acc: 0.9107\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 0.2295 - acc: 0.9132\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.2241 - acc: 0.9175\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.2256 - acc: 0.9141\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 0.2178 - acc: 0.9218\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.2129 - acc: 0.9203\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 4s 176ms/step - loss: 0.2117 - acc: 0.9221\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.2027 - acc: 0.9255\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.2136 - acc: 0.9209\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.2178 - acc: 0.9181\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 4s 172ms/step - loss: 0.2061 - acc: 0.9252\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 4s 174ms/step - loss: 0.1879 - acc: 0.9320\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 4s 168ms/step - loss: 0.1871 - acc: 0.9289\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.1783 - acc: 0.9329\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.2166 - acc: 0.9190\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.2196 - acc: 0.9181\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 4s 175ms/step - loss: 0.1847 - acc: 0.9301\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 4s 166ms/step - loss: 0.1736 - acc: 0.9326\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.1701 - acc: 0.9375\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.1668 - acc: 0.9387\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.1966 - acc: 0.9233\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.1714 - acc: 0.9353\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 4s 170ms/step - loss: 0.1599 - acc: 0.9387\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 4s 173ms/step - loss: 0.1739 - acc: 0.9347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b803a7950>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JphIbljuQAI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvCeu9qA8mGY"
      },
      "source": [
        "#########################################################################\n",
        "####################encoder 구조를 gru로 만들어보기######################\n",
        "#########################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZGcp-ARuHnk"
      },
      "source": [
        "#########################################################################\n",
        "####################encoder 구조를 cnn로 만들어보기######################\n",
        "#########################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}