{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week8_Lab7_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whispermy/novatus_academia/blob/main/Week8_Lab7_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOjujz601HcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995fc53d-8769-4434-863b-1e167f837311"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zswl7jRtGzkk"
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope=0):\n",
        "    return slope * time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "series = trend(time, 0.1)  \n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sTTIOCbyShY"
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Hl39rklkLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bd8d69-d445-4bf8-c9ed-11eaea2cc530"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 12s 23ms/step - loss: 21.5167 - mae: 22.0115\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 21.1522 - mae: 21.6444\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 20.7302 - mae: 21.2236\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 20.2834 - mae: 20.7757\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 19.7897 - mae: 20.2855\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 19.1782 - mae: 19.6696\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 18.2410 - mae: 18.7333\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 17.4825 - mae: 17.9748\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 17.1597 - mae: 17.6529\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 16.8547 - mae: 17.3463\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 16.5533 - mae: 17.0471\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 16.2565 - mae: 16.7524\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 15.9629 - mae: 16.4598\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 15.6593 - mae: 16.1548\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 15.3713 - mae: 15.8652\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 15.0752 - mae: 15.5697\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 14.7905 - mae: 15.2869\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 14.5229 - mae: 15.0178\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 14.2707 - mae: 14.7636\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 14.0293 - mae: 14.5217\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 13.8191 - mae: 14.3135\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 13.6084 - mae: 14.1032\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 13.4096 - mae: 13.9038\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 13.1859 - mae: 13.6794\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 12.9819 - mae: 13.4747\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 12.7278 - mae: 13.2184\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 12.4886 - mae: 12.9799\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 12.3459 - mae: 12.8362\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 11.9127 - mae: 12.4017\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 11.5934 - mae: 12.0835\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 11.2859 - mae: 11.7771\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 11.3520 - mae: 11.8418\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 10.5232 - mae: 11.0139\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 10.5497 - mae: 11.0379\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 10.0667 - mae: 10.5519\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 10.6445 - mae: 11.1369\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 10.2624 - mae: 10.7533\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 9.6822 - mae: 10.1703\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 9.1576 - mae: 9.6420\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 8.7008 - mae: 9.1866\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 8.2782 - mae: 8.7635\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 7.9342 - mae: 8.4188\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 7.6089 - mae: 8.0929\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 7.3643 - mae: 7.8504\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 7.2039 - mae: 7.6874\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.8901 - mae: 7.3726\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.6798 - mae: 7.1633\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.5776 - mae: 7.0597\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 6.2079 - mae: 6.6839\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.0391 - mae: 6.5180\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.9102 - mae: 6.3880\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.7769 - mae: 6.2585\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.6296 - mae: 6.1098\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.5201 - mae: 5.9943\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.3906 - mae: 5.8627\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.5555 - mae: 6.0293\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.2783 - mae: 5.7561\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 5.2566 - mae: 5.7348\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.1177 - mae: 5.5963\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.0499 - mae: 5.5242\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.3116 - mae: 5.7906\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.2180 - mae: 5.6976\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.0244 - mae: 5.4991\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 4.8398 - mae: 5.3145\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.2841 - mae: 5.7640\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.3670 - mae: 5.8503\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.1163 - mae: 6.5990\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.2426 - mae: 5.7265\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.4561 - mae: 5.9367\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 4.8406 - mae: 5.3132\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.7574 - mae: 6.2392\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.2817 - mae: 5.7606\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.9509 - mae: 7.4356\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.1186 - mae: 5.5972\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.3273 - mae: 5.8062\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 4.9569 - mae: 5.4370\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.8794 - mae: 6.3615\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.4690 - mae: 5.9475\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.5755 - mae: 6.0511\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.1457 - mae: 5.6279\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.6721 - mae: 6.1542\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.5962 - mae: 7.0810\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.4473 - mae: 6.9318\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 6.4293 - mae: 6.9123\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 5.6762 - mae: 6.1593\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 5.9608 - mae: 6.4396\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 8.1456 - mae: 8.6344\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 7.3520 - mae: 7.8385\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 7.0041 - mae: 7.4897\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 6.8820 - mae: 7.3634\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 6.9256 - mae: 7.4094\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 7.3751 - mae: 7.8624\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 10.6242 - mae: 11.1173\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 10.3501 - mae: 10.8405\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 7.1573 - mae: 7.6405\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 10.4951 - mae: 10.9878\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 10.3070 - mae: 10.7936\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 7.8970 - mae: 8.3830\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 11.3386 - mae: 11.8315\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 8.8786 - mae: 9.3653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkBsrsXMzoWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "4a9dd34d-0700-48bc-87e0-b93f56d244bd"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1e-08, 0.0001, 0.0, 30.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC5k1FXsUAkx"
      },
      "source": [
        "위에서 찾은 1e-5를 learning rate으로 해서 다시 학습해 보겠습니다. model.fit 에서 verbose=0으로 하면 화면에 학습 과정이 표현되지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uh-97bpLZCA"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9),metrics=[\"mae\"])\n",
        "history = model.fit(dataset,epochs=500,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff6IZL8qVGQc"
      },
      "source": [
        "학습된 모델로 예측을 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGDaND7z0ne"
      },
      "source": [
        "forecast = []\n",
        "results = []\n",
        "for time in range(len(series) - window_size):\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "forecast = forecast[split_time-window_size:]\n",
        "results = np.array(forecast)[:, 0, 0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfPeqI7rz4LD"
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUsdZB_tzDLe"
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, mae, 'r')\n",
        "plt.plot(epochs, loss, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "epochs_zoom = epochs[200:]\n",
        "mae_zoom = mae[200:]\n",
        "loss_zoom = loss[200:]\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot Zoomed MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
        "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ5nFvwaU_Om"
      },
      "source": [
        "이제 좀더 tuning을 해보겠습니다. learning rate을 바꾸거나, layer를 더 늘려보죠."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGaYFxXNEAK"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))\n",
        "model.fit(dataset,epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ3R8ysauz9e"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))\n",
        "model.fit(dataset,epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
